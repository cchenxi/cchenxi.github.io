<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>陈曦的技术博客</title><link>https://cchenxi.github.io/</link><description>Recent content on 陈曦的技术博客</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 17 Jun 2021 17:05:54 +0800</lastBuildDate><atom:link href="https://cchenxi.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>MySQL主从复制-异步复制</title><link>https://cchenxi.github.io/posts/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6/</link><pubDate>Thu, 17 Jun 2021 17:05:54 +0800</pubDate><guid>https://cchenxi.github.io/posts/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6-%E5%BC%82%E6%AD%A5%E5%A4%8D%E5%88%B6/</guid><description>复制是MySQL数据库提供的一种高可用高性能解决方案，一般用来建立大型应用（《MySQL技术内幕：innodb存储引擎（第二版）》）。
常见的主从复制方案有：异步复制、半同步复制、组复制。本文主要介绍传统的异步复制方式。
1. 环境准备 操作系统：macOS Big Sur 11.0.1
MySQL: mysql 5.7
为方便操作，这里使用docker来进行配置。配置3个MySQL实例，用于后续进行主从复制实验（1主2从）。
1.1. 拉取MySQL 5.7的镜像 docker pull mysql:5.7 1.2. 启动MySQL实例 启动 master 实例 docker run -d \ -p 3307:3306 \ -e MYSQL_ROOT_PASSWORD=123456 \ -e TZ=Asia/Shanghai \ -v ~/tools/mysql/master/data:/var/lib/mysql \ -v ~/tools/mysql/master/conf.d:/etc/mysql/conf.d \ --name mysql-5.7-master \ mysql:5.7 将MySQL数据文件挂在到本地目录 ~/tools/mysql/master/data，这样数据文件就可以直接在本地查看。
将MySQL配置文件目录挂在到本地目录 ~/tools/mysql/master/conf.d，这样就可以在本地自定义配置文件，而不需要每次修改配置都登入容器内部。
自定义配置文件 my-custom.cnf 如下，
[mysqld] server_id = 1 sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES log_bin=mysql-bin binlog-format=Row 启动 slave01 实例 docker run -d \ -p 3317:3306 \ -e MYSQL_ROOT_PASSWORD=123456 \ -e TZ=Asia/Shanghai \ -v ~/tools/mysql/slave01/data:/var/lib/mysql \ -v ~/tools/mysql/slave01/conf.</description></item><item><title>GC日志解读</title><link>https://cchenxi.github.io/posts/gc%E6%97%A5%E5%BF%97%E8%A7%A3%E8%AF%BB/</link><pubDate>Sat, 05 Jun 2021 11:04:00 +0800</pubDate><guid>https://cchenxi.github.io/posts/gc%E6%97%A5%E5%BF%97%E8%A7%A3%E8%AF%BB/</guid><description>为深入学习GC（Garbage Collection，垃圾回收），本文将使用一段测试代码来测试不同的GC策略下的执行情况，并对输出的GC日志做简要分析。
1. 测试环境 1.1. 操作系统及jdk版本 ➜ 01jvm git:(main) ✗ java -version java version &amp;#34;1.8.0_131&amp;#34; Java(TM) SE Runtime Environment (build 1.8.0_131-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode) 1.2. 测试代码 测试代码来源： https://github.com/JavaCourse00/JavaCourseCodes/blob/main/01jvm/GCLogAnalysis.java
import java.util.Random; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.LongAdder; /* 演示GC日志生成与解读 */ public class GCLogAnalysis { private static Random random = new Random(); public static void main(String[] args) { // 当前毫秒时间戳 long startMillis = System.currentTimeMillis(); // 持续运行毫秒数; 可根据需要进行修改 long timeoutMillis = TimeUnit.</description></item><item><title>Redis持久化、主从复制、哨兵、集群配置，一步一步走向高可用</title><link>https://cchenxi.github.io/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E8%B5%B0%E5%90%91%E9%AB%98%E5%8F%AF%E7%94%A8/</link><pubDate>Thu, 03 Jun 2021 21:31:18 +0800</pubDate><guid>https://cchenxi.github.io/posts/redis%E6%8C%81%E4%B9%85%E5%8C%96%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E4%B8%80%E6%AD%A5%E4%B8%80%E6%AD%A5%E8%B5%B0%E5%90%91%E9%AB%98%E5%8F%AF%E7%94%A8/</guid><description>1. Redis数据持久化 2. Redis主从复制：从单机到多节点 3. Redis Sentinel主从切换：走向高可用 3.1. 配置主从 参考步骤2. 配置一主一从两个Redis节点，主节点为127.0.0.1:6379，从节点为127.0.0.1:6380。
3.2. 配置sentinel的配置文件 sentinel0.conf
sentinel monitor mymaster 127.0.0.1 6379 2 sentinel down-after-milliseconds mymaster 10000 3.3. 启动一个sentinel节点 使用以下命令启动一个sentinel
redis-sentinel ./conf/sentinel0.conf 启动之后控制台输出如下内容
5643:X 13 Mar 2021 21:40:56.054 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 5643:X 13 Mar 2021 21:40:56.054 # Redis version=6.0.9, bits=64, commit=00000000, modified=0, pid=5643, just started 5643:X 13 Mar 2021 21:40:56.054 # Configuration loaded 5643:X 13 Mar 2021 21:40:56.055 * Increased maximum number of open files to 10032 (it was originally set to 256).</description></item></channel></rss>